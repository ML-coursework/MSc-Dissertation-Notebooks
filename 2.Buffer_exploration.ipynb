{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463f315d-01db-405d-bba3-dff46967e9dc",
   "metadata": {},
   "source": [
    "# <u>T-test and predictive logistic regression</u> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afc511-a412-48ca-b840-5bf1c9ab9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python packages and modules\n",
    "!pip install imgkit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import IPython.display as disp\n",
    "import imgkit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV\n",
    "from scipy.stats import ttest_ind\n",
    "from IPython.display import FileLink\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e9982-0b4c-49c6-9cae-9292e2bcb9dd",
   "metadata": {},
   "source": [
    "#### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ad7a5-82ed-4476-bebd-9bd877d1e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the buffer count (see Buffer_count.ipynb)\n",
    "buffer_metrics = gpd.read_file(\"buffer_metrics_lat_long.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eda55b-7b88-4bfa-8712-589bed74241b",
   "metadata": {},
   "source": [
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad3ab0-95ec-4928-9a2f-4c8563ec9253",
   "metadata": {},
   "source": [
    "# Checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b31ae0-3413-4d21-8e61-74e20f5bcee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_metrics.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a757931-4497-4b9c-a9ce-d748575d3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All records are present\n",
    "buffer_metrics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec29dee-fb7c-4385-a555-cc47e81feb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting relevant columns to numeric, coercing errors to NaN\n",
    "for col in ['Point ID', 'Building count', 'Road length', 'Bathymetry mean', 'Other points']:\n",
    "    buffer_metrics[col] = pd.to_numeric(buffer_metrics[col], errors='coerce')\n",
    "\n",
    "# Check again\n",
    "print(buffer_metrics.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393d448-062e-4dec-b9a2-70b09c7fdf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data lines up, 5 strandings, same lat long, different sizes and counts, same for the corresponding random point\n",
    "filtered_df = buffer_metrics[buffer_metrics['Point ID'] == 4451]\n",
    "filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61faa500-c1b9-41da-83dd-d4f0f2a5fb48",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a5558-2cd5-496e-a89f-54073e477598",
   "metadata": {},
   "source": [
    "# Scaling and transforming the data\n",
    "\n",
    "#### Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db36e9-e242-44cd-9862-db0ad291e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the warning output for astetics\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "# Replacing inf with NaN in the DataFrame\n",
    "buffer_metrics = buffer_metrics.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Sort so largest buffers are first, smallest last (drawn last = on top)\n",
    "order = ['5000m', '3000m', '1500m', '1000m', '500m']\n",
    "buffer_metrics_sorted = buffer_metrics.set_index('Buffer size').loc[order].reset_index()\n",
    "\n",
    "\n",
    "# Setting the colours to make it easier to see\n",
    "custom_palette = {\n",
    "    '500m':   '#E41A1C',\n",
    "    '1000m':  '#377EB8',\n",
    "    '1500m':  '#4DAF4A',\n",
    "    '3000m':  '#984EA3',\n",
    "    '5000m':  '#FF7F00'}\n",
    "\n",
    "#Creating the pairplot\n",
    "sns.pairplot(\n",
    "    data=buffer_metrics,\n",
    "    vars=['Building count', 'Road length', 'Bathymetry mean', 'Other points'],\n",
    "    hue='Buffer size',\n",
    "    palette=custom_palette)\n",
    "#Saving and displaying the plot\n",
    "plt.savefig(\"Method_results_images/T_test_Pairplot_Before_Log_Transform.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5348745-ca62-4895-b3a2-91987d2253ff",
   "metadata": {},
   "source": [
    "#### The pairplot shows a strong positive linear relationship between building count and road length across all buffer sizes. Human presence (buildings and roads) is inversely related to bathymetry, with higher human presence associated with shallower coastal zones. Larger buffers (5000 m) dominate with higher values and greater bathymetric variation, likely from covering both land and sea, while smaller buffers cluster at lower values but follow the same trends. The “other points” metric is highly skewed, with most buffers containing few additional points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1113b-e6c8-43ed-a2fa-07c3e107970d",
   "metadata": {},
   "source": [
    "#### Log-transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb7403-4772-4259-bd7a-be6be9d37fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Building count', 'Road length', 'Bathymetry mean', 'Other points']\n",
    "buffer_metrics[cols] = buffer_metrics[cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86f407-64b8-4327-961a-6309f3ca5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing correlations\n",
    "buffer_metrics[['Building count', 'Road length', 'Bathymetry mean', 'Other points']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c90a8-d318-4d91-911c-284745b4060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of buffer_metrics\n",
    "df_log = buffer_metrics.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454266ae-70da-4393-bac2-d7e0390ed865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log-transforming building count and road lenght to reduce skewness\n",
    "df_log['Building_trans'] = np.log1p(df_log['Building count'])\n",
    "df_log['Road_trans'] = np.log1p(df_log['Road length'])\n",
    "df_log['Bathymetry_trans'] = np.log1p(df_log['Bathymetry mean'])\n",
    "df_log['Other_points_trans'] = np.log1p(df_log['Other points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c3a66-f30d-4935-aaf3-5e771cc196c3",
   "metadata": {},
   "source": [
    "#### Dealing with bathymetric null records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8dcad-35b6-4277-b86e-da8f6cdfa8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771934f-a09c-4898-8fb9-6f8904921b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the missing 480 bathymetry_trans records (the same as the ones in the Buffer_count notebook) \n",
    "df_log[df_log['Bathymetry_trans'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15639d-0e1f-4bd5-aae2-940c0ad3bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing warning for aesthetics \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "# Replacing inf with NaN in the DataFrame\n",
    "buffer_metrics = buffer_metrics.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Sort so largest buffers are first, smallest last (drawn last = on top)\n",
    "order = ['5000m', '3000m', '1500m', '1000m', '500m']\n",
    "buffer_metrics_sorted = buffer_metrics.set_index('Buffer size').loc[order].reset_index()\n",
    "\n",
    "# Setting the colours to make it easier to see the differnt clusters\n",
    "custom_palette = {\n",
    "    '500m':   '#E41A1C',\n",
    "    '1000m':  '#377EB8',\n",
    "    '1500m':  '#4DAF4A',\n",
    "    '3000m':  '#984EA3',\n",
    "    '5000m':  '#FF7F00'}\n",
    "\n",
    "#Creating the pairplot\n",
    "sns.pairplot(\n",
    "    data=df_log,\n",
    "    vars=['Building_trans', 'Road_trans', 'Bathymetry_trans', 'Other_points_trans'],\n",
    "    hue='Buffer size',\n",
    "    palette=custom_palette)\n",
    "#Saving and displaying the plot\n",
    "plt.savefig(\"Method_results_images/T_test_Pairplot_After_Log_Transform.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c809284-54f0-4008-b2b2-6de792af7877",
   "metadata": {},
   "source": [
    "#### Pairplot shows reduction in skewness, improved comparability across buffer sizes, more linear relationships, equalised influence of predictors and clearer density patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd8a78-e79e-4d6e-8703-6fe1250f4d4d",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19568a-b13b-4b4e-ac60-1fe4b7a9b31b",
   "metadata": {},
   "source": [
    "# Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441de1ed-cd85-4de3-a3d4-93b566c23533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the ndarray back to a pandas DataFrame\n",
    "df_log = pd.DataFrame(df_log, columns=['Building_trans', 'Road_trans', 'Bathymetry_trans', 'Other_points_trans'])\n",
    "\n",
    "# Scaling the features with RobustScaler\n",
    "features_to_scale = ['Building_trans', 'Road_trans', 'Bathymetry_trans', 'Other_points_trans']\n",
    "scaler = RobustScaler()\n",
    "df_log[features_to_scale] = scaler.fit_transform(df_log[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336da97-356d-45da-a47f-e65a7d5be878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44294a2b-50e8-4d31-8139-958d609c86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the log-transformed and scaled columns back into the original DataFrame\n",
    "cols_to_add = ['Data', 'Buffer size', 'Buffer geometry', 'Point ID', 'Other points', 'Road length', 'Building count', 'Bathymetry mean', 'latitude','longitude']\n",
    "\n",
    "df_log = pd.concat(\n",
    "    [\n",
    "        buffer_metrics[cols_to_add].reset_index(drop=True),\n",
    "        df_log.reset_index(drop=True)],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70993a-08e4-47e3-a743-70361a99d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the new df\n",
    "df_log.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22822d69-b48d-4cf7-8b74-3062d0388303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows intact (minus the 480 from bathymetry columns)\n",
    "df_log.shape\n",
    "df_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142985e8-d8e1-4ffd-9471-2cfbf728b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932358f-ad09-44cb-825f-fa21db4a440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new df \n",
    "df_log = df_log.copy()\n",
    "\n",
    "# Saving to CSV\n",
    "df_log.to_csv('df_log.csv', index=False)\n",
    "\n",
    "# Display download link\n",
    "FileLink('df_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a198d9d-495a-4254-ae4d-dda6ff1093f0",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced04b2-59b6-4890-9033-6a58591a3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I added the latitude and longtitude for the points back into the DataFrame, and removed the larger 3000 and 5000 sized buffers\n",
    "df = gpd.read_file(\"df_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2c509-7454-465d-8be8-8da897f74ee8",
   "metadata": {},
   "source": [
    "#### Creating a GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd80ea-e3bf-4089-807e-d14173a3f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the Latitude and Longitude are numeric\n",
    "df[\"latitude\"] = pd.to_numeric(df[\"latitude\"], errors=\"coerce\")\n",
    "df[\"longitude\"] = pd.to_numeric(df[\"longitude\"], errors=\"coerce\")\n",
    "\n",
    "# Creating a Point geometry column\n",
    "df[\"Point geometry\"] = df.apply(lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1)\n",
    "\n",
    "# Making the GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"Point geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Preview\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284a707-2703-457e-b7a2-11be16703508",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5240ad-630b-4d11-b6da-1531dd21765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRS:\", gdf.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec88ef1-bc40-45fe-9b36-159a1d0f393d",
   "metadata": {},
   "source": [
    "#### Descriptive statistics and info for each buffer size, for both random and strandings, to get a feel for the breakdown of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1911340-ec9f-4eba-8bbe-1a82f8188f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the buffer size column and enforce order\n",
    "gdf['Buffer size'] = gdf['Buffer size'].str.replace('m', '').astype(int)\n",
    "buffer_order = [500, 1000, 1500, 3000, 5000]\n",
    "gdf['Buffer size'] = pd.Categorical(gdf['Buffer size'], categories=buffer_order, ordered=True)\n",
    "\n",
    "# Metrics to describe\n",
    "metrics = ['Other points', 'Road length', 'Building count', 'Bathymetry mean']\n",
    "for col in metrics:\n",
    "    gdf[col] = pd.to_numeric(gdf[col], errors='coerce')\n",
    "gdf = gdf.dropna(subset=metrics)\n",
    "\n",
    "# Generating .describe() per buffer size and data type\n",
    "for buffer_size in buffer_order:\n",
    "    for data_type in ['Strandings points', 'Random points']:\n",
    "        subset = gdf[(gdf['Buffer size'] == buffer_size) & (gdf['Data'] == data_type)]\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Descriptive Stats for {data_type} at {buffer_size}m\")\n",
    "        print(subset[metrics].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff202a7b-50e2-44a9-bc20-df3b468c6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring 'Buffer size' is treated as integer\n",
    "if gdf['Buffer size'].dtype == 'object':\n",
    "    gdf['Buffer size'] = gdf['Buffer size'].str.replace('m', '').astype(int)\n",
    "\n",
    "# Defining hte buffer order \n",
    "buffer_order = [500, 1000, 1500, 3000, 5000]\n",
    "gdf['Buffer size'] = pd.Categorical(gdf['Buffer size'], categories=buffer_order, ordered=True)\n",
    "\n",
    "# Looping and printing .info()\n",
    "for buffer_size in buffer_order:\n",
    "    for data_type in ['Strandings points', 'Random points']:\n",
    "        subset = gdf[(gdf['Buffer size'] == buffer_size) & (gdf['Data'] == data_type)]\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\".info() for {data_type} at {buffer_size}m\")\n",
    "        print(\"=\"*60)\n",
    "        subset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bab993-d1e8-418f-992e-28647158b6b3",
   "metadata": {},
   "source": [
    "# Strandings points vs random points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9034f90-cbf1-4338-bb03-f8607d5670c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing warnings for aesthetics \n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*observed=False is deprecated.*\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*use_inf_as_na option is deprecated.*\")\n",
    "\n",
    "\n",
    "\n",
    "# Setting the buffer order\n",
    "buffer_order = [500, 1000, 1500, 3000, 5000] \n",
    "gdf['Buffer size'] = pd.Categorical(gdf['Buffer size'], categories=buffer_order, ordered=True)\n",
    "gdf['Buffer size (m)'] = gdf['Buffer size'].astype(str) + 'm'\n",
    "\n",
    "# Ensuring metric columns are numeric\n",
    "metrics = ['Other points', 'Road length', 'Building count', 'Bathymetry mean']\n",
    "for col in metrics:\n",
    "    gdf[col] = pd.to_numeric(gdf[col], errors='coerce')\n",
    "\n",
    "gdf.dropna(subset=metrics, inplace=True)\n",
    "\n",
    "# Setting the titles\n",
    "titles = [\n",
    "    'Other Points: Strandings vs Random',\n",
    "    'Road Length: Strandings vs Random',\n",
    "    'Building Count: Strandings vs Random',\n",
    "    'Bathymetry Mean: Strandings vs Random'\n",
    "]\n",
    "\n",
    "# Plotting the barcharts\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = {'Strandings points': 'steelblue', 'Random points': 'darkorange'}\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    grouped = gdf.groupby(['Buffer size (m)', 'Data'])[metric].sum().reset_index()\n",
    "    # Sort by buffer order for plotting\n",
    "    grouped['Buffer size (m)'] = pd.Categorical(\n",
    "        grouped['Buffer size (m)'],\n",
    "        categories=[f\"{b}m\" for b in buffer_order],\n",
    "        ordered=True\n",
    "    )\n",
    "    sns.barplot(\n",
    "        data=grouped,\n",
    "        x='Buffer size (m)', y=metric, hue='Data',\n",
    "        palette=palette, ax=ax\n",
    "    )\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xlabel(\"Buffer Size\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend(title='Data Type')\n",
    "    \n",
    "plt.tight_layout()    \n",
    "plt.savefig(\"Method_results_images/T_test_Barcharts_Random_vs_Strandings.png\", dpi=150, bbox_inches=\"tight\")\n",
    "#Visulising \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d2ac7-9067-4729-a44b-580d07d46ab2",
   "metadata": {},
   "source": [
    "#### Across all buffer sizes, strandings points consistently show higher counts of other points, road length, and building count compared to random points, with differences becoming more pronounced as buffer size increases. For bathymetry random points are more often located at deeper waters, which fits with our understanding that strandings occur in shallower waters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84943b8f-b871-4078-a1bd-b9b540bf1379",
   "metadata": {},
   "source": [
    "# Welch's t-tests\n",
    "#### To see if strandings and random points differ significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfe938-0d34-4a8c-ac06-8ef84e7568c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_log.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb321f-0638-4e6f-a55e-a655d355063a",
   "metadata": {},
   "source": [
    "#### For each buffer size and metric, I compared strandings and random locations with Welch’s two-sample t-test (unequal variances), which is robust to differences in variance and sample size between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16dd7e5-7dff-464e-b427-7fb04d2ac982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the relevant columns to test\n",
    "metrics = ['Building_trans', 'Road_trans', 'Bathymetry_trans', 'Other_points_trans']\n",
    "buffer_sizes = df_log['Buffer size'].unique()\n",
    "\n",
    "# Storing the results\n",
    "results = []\n",
    "# Looping over the buffers for strandings and random, skipping any missing data\n",
    "for buffer in buffer_sizes:\n",
    "    for metric in metrics:\n",
    "        strandings_df = df_log[\n",
    "            (df_log['Data'] == 'Strandings points') &\n",
    "            (df_log['Buffer size'] == buffer)]\n",
    "\n",
    "        randoms_df = df_log[\n",
    "            (df_log['Data'] == 'Random points') &\n",
    "            (df_log['Buffer size'] == buffer)]\n",
    "\n",
    "\n",
    "        if strandings_df.empty or randoms_df.empty:\n",
    "            print(f\"Skipping buffer {buffer}, metric {metric} (no data)\")\n",
    "            continue\n",
    "\n",
    "        strandings = strandings_df[metric].dropna()\n",
    "        randoms = randoms_df[metric].dropna()\n",
    "\n",
    "        if strandings.empty or randoms.empty:\n",
    "            print(f\"Skipping buffer {buffer}, metric {metric} (no non-NA data)\")\n",
    "            continue\n",
    "# Running Welch's test, and collecting the results\n",
    "        t_stat, p_val = ttest_ind(strandings, randoms, equal_var=False)\n",
    "\n",
    "        results.append({\n",
    "            'Buffer size': buffer,\n",
    "            'Metric': metric,\n",
    "            't-statistic': round(t_stat, 3),\n",
    "            'p-value': round(p_val, 3)})\n",
    "\n",
    "\n",
    "# Creating a results DataFrame\n",
    "t_test_df = pd.DataFrame(results)\n",
    "print(t_test_df)\n",
    "\n",
    "#os.makedirs(\"Method_results_images\", exist_ok=True)\n",
    "#Saving the table for the write up\n",
    "t_test_df_sorted = t_test_df.sort_values(['Metric','Buffer size']).reset_index(drop=True)\n",
    "t_test_df_sorted.to_html(\n",
    "    \"Method_results_images/T_tests_Results_By_Buffer.html\",\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7840c-0c7c-403e-b9cc-3f48e662e592",
   "metadata": {},
   "source": [
    "#### Key points: Strandings locations appear more “human-present” (more nearby points, roads, buildings) and in shallower water than random locations, with the anthropogenic contrasts strongest at smaller spatial scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcac2c4-e590-4f50-acf1-a55012dbf1d4",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb3ea1-db2a-43aa-ab2f-4a46baf45164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new df\n",
    "t_test_df = t_test_df.copy()\n",
    "\n",
    "# Saving to CSV\n",
    "t_test_df.to_csv('t_test_df.csv', index=False)\n",
    "\n",
    "# Display download link\n",
    "FileLink('t_test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43826d79-c41b-4b24-9cee-e7a0019e62ea",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c3726-3048-4a73-a32c-52d6232fa8e3",
   "metadata": {},
   "source": [
    "# Cohen's d \n",
    "#### Carrying out cohen's d statistical analysis to quantify the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878680d-a0c8-44c8-b84f-80619a771c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the relevant columns to test\n",
    "metrics = ['Other points', 'Road length', 'Building count', 'Bathymetry mean']\n",
    "buffer_sizes = buffer_metrics['Buffer size'].unique()\n",
    "# Storing the results\n",
    "results = []\n",
    "# Looping over the buffers for strandings and random, skipping any missing data\n",
    "for buffer in buffer_sizes:\n",
    "    for metric in metrics:\n",
    "        # Subset data for strandings and random points\n",
    "        strandings = buffer_metrics[\n",
    "            (buffer_metrics['Data'] == 'Strandings points') &\n",
    "            (buffer_metrics['Buffer size'] == buffer)\n",
    "        ][metric].dropna()\n",
    "\n",
    "        randoms = buffer_metrics[\n",
    "            (buffer_metrics['Data'] == 'Random points') &\n",
    "            (buffer_metrics['Buffer size'] == buffer)\n",
    "        ][metric].dropna()\n",
    "\n",
    "        # Running Welch's t-test\n",
    "        t_stat, p_val = ttest_ind(strandings, randoms, equal_var=False)\n",
    "\n",
    "        # Testing the means and stds for effect size\n",
    "        mean1 = strandings.mean()\n",
    "        mean2 = randoms.mean()\n",
    "        std1 = strandings.std()\n",
    "        std2 = randoms.std()\n",
    "        n1 = len(strandings)\n",
    "        n2 = len(randoms)\n",
    "\n",
    "        # Pooling standard deviation\n",
    "        pooled_std = np.sqrt(((n1 - 1)*std1**2 + (n2 - 1)*std2**2) / (n1 + n2 - 2))\n",
    "\n",
    "        # Cohen's d\n",
    "        if pooled_std > 0:\n",
    "            cohens_d = (mean1 - mean2) / pooled_std\n",
    "        else:\n",
    "            cohens_d = np.nan\n",
    "        # Collecting results\n",
    "        results.append({\n",
    "            'Buffer size': buffer,\n",
    "            'Metric': metric,\n",
    "            'Strandings mean': round(mean1, 3),\n",
    "            'Randoms mean': round(mean2, 3),\n",
    "            't-statistic': round(t_stat, 3),\n",
    "            'p-value': round(p_val, 3),\n",
    "            'Cohen d': round(cohens_d, 3)})\n",
    "\n",
    "# Creating a DataFrame of results\n",
    "cohens_d_df = pd.DataFrame(results)\n",
    "\n",
    "# Showing results\n",
    "print(cohens_d_df)\n",
    "\n",
    "#os.makedirs(\"Method_results_images\", exist_ok=True)\n",
    "#Saving the results for write up\n",
    "cohens_d_df_sorted = cohens_d_df.sort_values(['Metric','Buffer size']).reset_index(drop=True)\n",
    "cohens_d_df_sorted.to_html(\n",
    "    \"Method_results_images/T_tests_Cohens_D_Results_By_Buffer.html\",\n",
    "    index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d840b7-0dfd-4ea9-be87-dcec444531f1",
   "metadata": {},
   "source": [
    "#### Across all buffer sizes, strandings occur in environments with more nearby points, longer road length, and higher building counts than random locations, while being associated with shallower bathymetry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da186cca-5b4f-410a-b43a-9c72eabca53a",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef3af0-aa5f-46e8-be98-742d6542effd",
   "metadata": {},
   "source": [
    "# Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9299c-fafd-4e26-926f-9dca8ea3d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure seaborn style is set\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Listing the metrics to plot\n",
    "metrics = ['Building_trans', 'Road_trans', 'Bathymetry_trans', 'Other_points_trans']\n",
    "\n",
    "# Looping over those metrics\n",
    "for metric in metrics:\n",
    "    g = sns.catplot(\n",
    "        x=\"Data\",\n",
    "        y=metric,\n",
    "        col=\"Buffer size\",\n",
    "        data=df_log,\n",
    "        kind=\"box\",\n",
    "        col_wrap=3,\n",
    "        height=4,\n",
    "        palette=\"pastel\",\n",
    "        sharey=False)\n",
    "#Formatting the boxplots    \n",
    "    g.fig.subplots_adjust(top=0.85)\n",
    "    g.fig.suptitle(f\"{metric} by Data Type and Buffer Size\", fontsize=16)\n",
    "    g.set_axis_labels(\"Point Type\", metric)\n",
    "# Saving and displaying the boxplots\n",
    "    plt.savefig(\"Method_results_images/T_test_Boxplots_Best_Buffer.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac006b-fd6b-4e48-a6b0-57b6589aa69f",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8ac2bd-881e-4719-b7f6-92f9923c79ad",
   "metadata": {},
   "source": [
    "# Logistic Regression Classification\n",
    "\n",
    "#### Predicting if a point is a random point or a stranding point to assess predictive performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42537032-f4f8-492d-afe7-c405d835e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data for analysis\n",
    "df_model = df_log.copy()\n",
    "df_model['is_stranding'] = df_model['Data'].apply(lambda x: 1 if x == 'Strandings points' else 0)\n",
    "#Defining the features\n",
    "features = ['Building_trans', 'Road_trans', 'Bathymetry_trans', 'Other_points_trans']\n",
    "df_model = df_model.dropna(subset=features + ['is_stranding'])\n",
    "# Defining inputs and target\n",
    "X = df_model[features]\n",
    "y = df_model['is_stranding']\n",
    "# Train/test split (with stratification to keep the class balance the same in train and test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "base_lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    base_lr, X_train, y_train,\n",
    "    cv=cv,\n",
    "    scoring=['accuracy', 'roc_auc'],\n",
    "    return_train_score=False)\n",
    "# Printing ± std for cross-validation accuracy and ROC AUC to show average performance and variability\n",
    "print(f\"CV Accuracy: {cv_scores['test_accuracy'].mean():.3f} ± {cv_scores['test_accuracy'].std():.3f}\")\n",
    "print(f\"CV ROC AUC: {cv_scores['test_roc_auc'].mean():.3f} ± {cv_scores['test_roc_auc'].std():.3f}\")\n",
    "\n",
    "\n",
    "# Small hyperparameter search for C using ROC AUC\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}  # 0.001 ... 1000\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "#Printing the results\n",
    "print(f\"Best C from CV: {grid.best_params_['C']}  |  Best CV ROC AUC: {grid.best_score_:.3f}\")\n",
    "\n",
    "# Fitting the best model on the full training set, evaluate on test\n",
    "best_model.fit(X_train, y_train)\n",
    "# Class prediction and predicted probabilities for teh positive class\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "# Displaying the results\n",
    "print(\"Test Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Test ROC AUC:\", round(roc_auc_score(y_test, y_prob), 3))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "# Creating a confusion matrix for the write up\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=[\"Random\", \"Stranding\"], yticklabels=[\"Random\", \"Stranding\"])\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\"); plt.title(\"Confusion Matrix (Logistic Regression)\")\n",
    "os.makedirs(\"Method_results_images\", exist_ok=True)\n",
    "plt.savefig(\"Method_results_images/T_test_Confusion_Matrix_LogReg_CV.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ae599-875a-4404-b227-80d8153954b5",
   "metadata": {},
   "source": [
    "#### Results suggests logistic regression is a moderately good at seperating classes but isn't highly predictive (Accuracy ~65%, ROC AUC ~0.71). It distinguishes between random and stranding points better than chance, but there’s substantial overlap between the classes, leading to balanced but modest precision/recall for both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c62709-ec03-446e-8869-78e4bcbc78a9",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "#### To compare a linear and a non-linear approach, we trained a Random Forest classifier on the same feature set and evaluated it both on the hold-out test set and with 5-fold stratified cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bfcdf-0f3a-40b7-90ff-211c5c110a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data for analysis\n",
    "df_model = df_log.copy()\n",
    "df_model['is_stranding'] = df_model['Data'].apply(lambda x: 1 if x == 'Strandings points' else 0)\n",
    "#Defining the features\n",
    "features = ['Building_trans', 'Road_trans', 'Bathymetry_trans', 'Other_points_trans']\n",
    "df_model = df_model.dropna(subset=features + ['is_stranding'])\n",
    "# Defining inputs and target\n",
    "X = df_model[features]\n",
    "y = df_model['is_stranding']\n",
    "# Train/test split (with stratification to keep the class balance the same in train and test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "base_rf = RandomForestClassifier(\n",
    "    n_estimators=300, random_state=42, n_jobs=-1)\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    base_rf, X_train, y_train,\n",
    "    cv=cv,\n",
    "    scoring=['accuracy', 'roc_auc'],\n",
    "    return_train_score=False,\n",
    "    n_jobs=-1)\n",
    "# Printing ± std for cross-validation accuracy and ROC AUC to show average performance and variability\n",
    "print(f\"RF CV Accuracy: {cv_scores['test_accuracy'].mean():.3f} ± {cv_scores['test_accuracy'].std():.3f}\")\n",
    "print(f\"RF CV ROC AUC: {cv_scores['test_roc_auc'].mean():.3f} ± {cv_scores['test_roc_auc'].std():.3f}\")\n",
    "\n",
    "\n",
    "#Small hyperparameter search using ROC AUC\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 600],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'max_features': ['sqrt', 0.5]}  # 'sqrt' or 50% of features}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "#Printing results\n",
    "print(f\"Best RF params: {grid.best_params_}\")\n",
    "print(f\"Best CV ROC AUC: {grid.best_score_:.3f}\")\n",
    "\n",
    "# Fitting the best Random Forest on training set; evaluating on the test set\n",
    "best_rf.fit(X_train, y_train)\n",
    "# Class prediction and predicted probabilities for teh positive class\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_prob = best_rf.predict_proba(X_test)[:, 1]\n",
    "# Displaying the results\n",
    "print(\"Test Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Test ROC AUC:\", round(roc_auc_score(y_test, y_prob), 3))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "# Creating a confusion matrix for the write up\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=[\"Random\", \"Stranding\"], yticklabels=[\"Random\", \"Stranding\"])\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\"); plt.title(\"Confusion Matrix (Random Forest)\")\n",
    "os.makedirs(\"Method_results_images\", exist_ok=True)\n",
    "plt.savefig(\"Method_results_images/T_test_Confusion_Matrix_Random_Forest_CV.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9a0dd-02bf-4d43-80eb-65c7f75230c9",
   "metadata": {},
   "source": [
    "#### The Random Forest model significantly outperforms Logistic Regression (Accuracy: 80% vs. 65%, ROC AUC: 0.885 vs. 0.707). It achieves balanced precision/recall for both classes and greatly reduces misclassifications, showing it captures the relationship between predictors and strandings far better than the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef95827-77b6-45e0-a5ec-9555fe91a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output folder exists\n",
    "os.makedirs(\"Method_results_images\", exist_ok=True)\n",
    "\n",
    "features = ['Building_trans', 'Road_trans', 'Bathymetry_trans', 'Other_points_trans']\n",
    "buffer_sizes = ['500m', '1000m', '1500m', '3000m', '5000m']\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for buffer in buffer_sizes:\n",
    "    # Subset and clean\n",
    "    subset = df_log[df_log['Buffer size'] == buffer].dropna(subset=features + ['Data']).copy()\n",
    "    subset['is_stranding'] = (subset['Data'] == 'Strandings points').astype(int)\n",
    "\n",
    "    X = subset[features]\n",
    "    y = subset['is_stranding']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # --- Logistic Regression ---\n",
    "    logreg = LogisticRegression(max_iter=1000)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    logreg_cv_acc = cross_val_score(logreg, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    logreg_cv_auc = cross_val_score(logreg, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    results_list.append({\n",
    "        \"Buffer size (m)\": buffer.replace(\"m\",\"\"),\n",
    "        \"Model\": \"Logistic Regression\",\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred), 3),\n",
    "        \"ROC AUC\": round(roc_auc_score(y_test, y_prob), 3),\n",
    "        \"CV Accuracy\": f\"{logreg_cv_acc.mean():.3f} ± {logreg_cv_acc.std():.3f}\",\n",
    "        \"CV ROC AUC\": f\"{logreg_cv_auc.mean():.3f} ± {logreg_cv_auc.std():.3f}\"\n",
    "    })\n",
    "\n",
    "    # --- Random Forest ---\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc_cv = cross_val_score(rf, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    auc_cv = cross_val_score(rf, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    results_list.append({\n",
    "        \"Buffer size (m)\": buffer.replace(\"m\",\"\"),\n",
    "        \"Model\": \"Random Forest\",\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred_rf), 3),\n",
    "        \"ROC AUC\": round(roc_auc_score(y_test, y_prob_rf), 3),\n",
    "        \"CV Accuracy\": f\"{acc_cv.mean():.3f} ± {acc_cv.std():.3f}\",\n",
    "        \"CV ROC AUC\": f\"{auc_cv.mean():.3f} ± {auc_cv.std():.3f}\"\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Save as interactive HTML\n",
    "html_path = \"Method_results_images/T_test_LogReg_vs_RanFor_By_Buffer.html\"\n",
    "results_df.to_html(html_path, index=False, justify=\"center\")\n",
    "\n",
    "# Show nice table\n",
    "import IPython.display as disp\n",
    "disp.display(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8d1f8-4539-4d6f-a02d-18079dc260ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance data\n",
    "buffer_sizes = ['500m', '1000m', '1500m', '3000m', '5000m']\n",
    "\n",
    "# Logistic Regression results\n",
    "logreg_accuracy = [0.754, 0.741, 0.726, 0.706, 0.694]\n",
    "logreg_roc_auc = [0.824, 0.808, 0.798, 0.770, 0.745]\n",
    "logreg_cv_accuracy = [0.753, 0.746, 0.734, 0.713, 0.696]\n",
    "logreg_cv_roc_auc = [0.823, 0.813, 0.803, 0.775, 0.750]\n",
    "\n",
    "# Random Forest results\n",
    "rf_accuracy = [0.779, 0.811, 0.828, 0.870, 0.903]\n",
    "rf_roc_auc = [0.860, 0.891, 0.909, 0.942, 0.966]\n",
    "rf_cv_accuracy = [0.782, 0.817, 0.836, 0.877, 0.908]\n",
    "rf_cv_roc_auc = [0.864, 0.897, 0.916, 0.950, 0.970]\n",
    "\n",
    "# Assemble into DataFrames for plotting\n",
    "df_logreg = pd.DataFrame({\n",
    "    'Buffer Size': buffer_sizes,\n",
    "    'Accuracy': logreg_accuracy,\n",
    "    'ROC AUC': logreg_roc_auc,\n",
    "    'CV Accuracy': logreg_cv_accuracy,\n",
    "    'CV ROC AUC': logreg_cv_roc_auc})\n",
    "\n",
    "df_rf = pd.DataFrame({\n",
    "    'Buffer Size': buffer_sizes,\n",
    "    'Accuracy': rf_accuracy,\n",
    "    'ROC AUC': rf_roc_auc,\n",
    "    'CV Accuracy': rf_cv_accuracy,\n",
    "    'CV ROC AUC': rf_cv_roc_auc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a789152-20b1-4108-8765-0bbf4e89f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating visulisation\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_logreg['Buffer Size'], df_logreg['Accuracy'], marker='o', label='LogReg Accuracy')\n",
    "plt.plot(df_logreg['Buffer Size'], df_logreg['CV Accuracy'], marker='o', linestyle='--', label='logreg CV Accuracy')\n",
    "plt.plot(df_rf['Buffer Size'], df_rf['Accuracy'], marker='o', label='RF Accuracy')\n",
    "plt.plot(df_rf['Buffer Size'], df_rf['CV Accuracy'], marker='o', linestyle='--', label='RF CV Accuracy')\n",
    "plt.title(\"Model Accuracy vs Buffer Size\")\n",
    "plt.xlabel(\"Buffer Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# ROC AUC comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df_logreg['Buffer Size'], df_logreg['ROC AUC'], marker='o', label='LogReg ROC AUC')\n",
    "plt.plot(df_logreg['Buffer Size'], df_logreg['CV ROC AUC'], marker='o', linestyle='--', label='logreg CV ROC AUC')\n",
    "plt.plot(df_rf['Buffer Size'], df_rf['ROC AUC'], marker='o', label='RF ROC AUC')\n",
    "plt.plot(df_rf['Buffer Size'], df_rf['CV ROC AUC'], marker='o', linestyle='--', label='RF CV ROC AUC')\n",
    "plt.title(\"Model ROC AUC vs Buffer Size\")\n",
    "plt.xlabel(\"Buffer Size\")\n",
    "plt.ylabel(\"ROC AUC\")\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Method_results_images/T_test_linegraph_Model_Accuracy_ROCAUC.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa2e11-41e1-4f2c-b712-4d776c8dfd87",
   "metadata": {},
   "source": [
    "#### These plots show how prediction performance changes with buffer size. Logistic Regression performs worse as buffers get larger, with both accuracy and ROC AUC dropping, while Random Forest improves steadily, reaching very high accuracy and discrimination (ROC AUC) at larger buffers. This suggests Random Forest captures complex, non-linear relationships that Logistic Regression misses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4492e-4704-4e75-98cb-4eaecb328057",
   "metadata": {},
   "source": [
    "## Mapping which points were predicted correctly for the larger 5000m buffer with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad126114-f889-4532-9ff3-9a3a43182e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing buffer size and features\n",
    "buffer = \"5000m\"\n",
    "features = ['Building_trans','Road_trans','Bathymetry_trans','Other_points_trans']\n",
    "\n",
    "# Subset + label\n",
    "subset = (df_log[df_log['Buffer size'] == buffer]\n",
    "          .dropna(subset=features + ['Data'])\n",
    "          .copy())\n",
    "subset['is_stranding'] = (subset['Data'] == 'Strandings points').astype(int)\n",
    "\n",
    "X = subset[features]\n",
    "y = subset['is_stranding']\n",
    "\n",
    "# Running Split + fit for Random Forest\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Creating a results DataFrame \n",
    "test_idx = X_test.index\n",
    "results = subset.loc[test_idx].copy()\n",
    "results['y_true'] = y_test\n",
    "results['y_pred'] = y_pred\n",
    "results['correct'] = (results['y_true'] == results['y_pred'])\n",
    "\n",
    "# Coordinates \n",
    "if 'geometry' not in results.columns and 'geometry' in gdf.columns:\n",
    "    results = results.merge(\n",
    "        gdf[['Point ID','Buffer size','geometry']],\n",
    "        on=['Point ID','Buffer size'], how='left')\n",
    "\n",
    "if 'geometry' in results.columns:\n",
    "    results['latitude']  = results.get('latitude',  results.geometry.y)\n",
    "    results['longitude'] = results.get('longitude', results.geometry.x)\n",
    "\n",
    "for col in ['latitude','longitude']:\n",
    "    if col in results.columns:\n",
    "        results[col] = (results[col].astype(str).str.strip().str.replace(',','', regex=False))\n",
    "        results[col] = pd.to_numeric(results[col], errors='coerce')\n",
    "\n",
    "results = results.dropna(subset=['latitude','longitude'])\n",
    "\n",
    "# Map\n",
    "map_center = [results['latitude'].mean(), results['longitude'].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=5, tiles=\"CartoDB positron\")\n",
    "\n",
    "# building the oucomes\n",
    "def outcome(r):\n",
    "    if r['y_true']==1 and r['y_pred']==1: return \"Stranding→Stranding\"\n",
    "    if r['y_true']==0 and r['y_pred']==1: return \"Random→Stranding\"\n",
    "    if r['y_true']==1 and r['y_pred']==0: return \"Stranding→Random\"\n",
    "    return \"Random→Random\"\n",
    "\n",
    "results['outcome'] = results.apply(outcome, axis=1)\n",
    "\n",
    "layers = {\n",
    "    \"Stranding→Stranding\" : (\"#1b9e77\", True),\n",
    "    \"Random→Stranding\"    : (\"#d95f02\", True),\n",
    "    \"Stranding→Random\"    : (\"#7570b3\", True),\n",
    "    \"Random→Random\"       : (\"#66a61e\", False)}\n",
    "\n",
    "fgs = {name: folium.FeatureGroup(name=name, show=show) for name, (_, show) in layers.items()}\n",
    "\n",
    "for _, r in results.iterrows():\n",
    "    color = layers[r['outcome']][0]\n",
    "    folium.CircleMarker(\n",
    "        [float(r['latitude']), float(r['longitude'])],\n",
    "        radius=4, color=color, fill=True, fill_opacity=0.7,\n",
    "        popup=f\"{r['outcome']} | True: {int(r['y_true'])}, Pred: {int(r['y_pred'])}\"\n",
    "    ).add_to(fgs[r['outcome']])\n",
    "\n",
    "for fg in fgs.values():\n",
    "    fg.add_to(m)\n",
    "# Adding clickable layer\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "# Adding legend\n",
    "counts = results['outcome'].value_counts()\n",
    "legend_html = f\"\"\"\n",
    "<div style=\"\n",
    "  position: fixed; bottom: 20px; left: 20px; z-index: 9999;\n",
    "  background: white; padding: 10px 12px; border: 1px solid #ccc;\n",
    "  border-radius: 6px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);\n",
    "  font-size: 13px;\">\n",
    "  <div style=\"font-weight:600; margin-bottom:6px;\">Prediction outcome (Random Forest)</div>\n",
    "  {''.join(\n",
    "    f'<div style=\"display:flex; align-items:center; margin:3px 0;\">'\n",
    "    f'<span style=\"display:inline-block; width:14px; height:14px; '\n",
    "    f'background:{layers[name][0]}; margin-right:6px; border:1px solid #888;\"></span>'\n",
    "    f'{name} (n={int(counts.get(name,0))})</div>'\n",
    "    for name in layers.keys()\n",
    "  )}\n",
    "</div>\n",
    "\"\"\"\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "#Displaying the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86663d0-712c-4ff4-a515-94e7eeb2bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the map\n",
    "m.save(\"Method_results_images/T_test_Random_Forest_Predictions_Outcome.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272c312-c85f-4348-8daa-ff257c9044c4",
   "metadata": {},
   "source": [
    "#### Saved as a link with Netlify [Random Forest predictions outcome link](https://random-forest-predictions.netlify.app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784092f3-576f-4d8c-80d8-39cf630a3b50",
   "metadata": {},
   "source": [
    "# Continues in 3.Kmeans notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
